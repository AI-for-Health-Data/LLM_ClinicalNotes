{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c99848b6-9500-47cd-a1be-6cc389c217c4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in /users/svats/ollama_conda_env/lib/python3.11/site-packages (0.3.18)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.24-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchainhub\n",
      "  Downloading langchainhub-0.1.21-py3-none-any.whl.metadata (659 bytes)\n",
      "Requirement already satisfied: langchain-core in /users/svats/ollama_conda_env/lib/python3.11/site-packages (0.3.47)\n",
      "Collecting langserve\n",
      "  Downloading langserve-0.3.1-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from langgraph) (2.0.21)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.2,>=0.1.1 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from langgraph) (0.1.3)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from langgraph) (0.1.58)\n",
      "Collecting langchain-core\n",
      "  Downloading langchain_core-0.3.57-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from langchain) (0.3.18)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from langchainhub) (24.2)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
      "  Downloading types_requests-2.32.0.20250328-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from langchain-core) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.23.0 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from langserve) (0.28.1)\n",
      "Requirement already satisfied: orjson<4,>=2 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from langserve) (3.10.15)\n",
      "Requirement already satisfied: anyio in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from httpx<1.0,>=0.23.0->langserve) (4.8.0)\n",
      "Requirement already satisfied: certifi in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from httpx<1.0,>=0.23.0->langserve) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from httpx<1.0,>=0.23.0->langserve) (1.0.7)\n",
      "Requirement already satisfied: idna in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from httpx<1.0,>=0.23.0->langserve) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from httpcore==1.*->httpx<1.0,>=0.23.0->langserve) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: greenlet>=1 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from anyio->httpx<1.0,>=0.23.0->langserve) (1.3.1)\n",
      "Downloading langchain-0.3.24-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchainhub-0.1.21-py3-none-any.whl (5.2 kB)\n",
      "Downloading langchain_core-0.3.57-py3-none-any.whl (437 kB)\n",
      "Downloading langserve-0.3.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading types_requests-2.32.0.20250328-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: types-requests, langchainhub, langchain-core, langserve, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.47\n",
      "    Uninstalling langchain-core-0.3.47:\n",
      "      Successfully uninstalled langchain-core-0.3.47\n",
      "Successfully installed langchain-0.3.24 langchain-core-0.3.57 langchain-text-splitters-0.3.8 langchainhub-0.1.21 langserve-0.3.1 types-requests-2.32.0.20250328\n",
      "Collecting openllm-client\n",
      "  Downloading openllm_client-0.5.7-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: requests in /users/svats/ollama_conda_env/lib/python3.11/site-packages (2.32.3)\n",
      "Requirement already satisfied: anyio in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from openllm-client) (4.8.0)\n",
      "Requirement already satisfied: distro in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from openllm-client) (1.9.0)\n",
      "Requirement already satisfied: httpx in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from openllm-client) (0.28.1)\n",
      "Collecting openllm-core (from openllm-client)\n",
      "  Downloading openllm_core-0.5.7-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: sniffio>=1.1 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from anyio->openllm-client) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from anyio->openllm-client) (4.12.2)\n",
      "Requirement already satisfied: httpcore==1.* in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from httpx->openllm-client) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from httpcore==1.*->httpx->openllm-client) (0.14.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from openllm-core->openllm-client) (25.1.0)\n",
      "Collecting deepmerge (from openllm-core->openllm-client)\n",
      "  Downloading deepmerge-2.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting inflection (from openllm-core->openllm-client)\n",
      "  Downloading inflection-0.5.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting mypy-extensions (from openllm-core->openllm-client)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: orjson in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from openllm-core->openllm-client) (3.10.15)\n",
      "Requirement already satisfied: packaging in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from openllm-core->openllm-client) (24.2)\n",
      "Requirement already satisfied: pydantic>2 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from openllm-core->openllm-client) (2.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from pydantic>2->openllm-core->openllm-client) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /users/svats/ollama_conda_env/lib/python3.11/site-packages (from pydantic>2->openllm-core->openllm-client) (2.27.2)\n",
      "Downloading openllm_client-0.5.7-py3-none-any.whl (17 kB)\n",
      "Downloading openllm_core-0.5.7-py3-none-any.whl (71 kB)\n",
      "Downloading deepmerge-2.0-py3-none-any.whl (13 kB)\n",
      "Downloading inflection-0.5.1-py2.py3-none-any.whl (9.5 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: mypy-extensions, inflection, deepmerge, openllm-core, openllm-client\n",
      "Successfully installed deepmerge-2.0 inflection-0.5.1 mypy-extensions-1.1.0 openllm-client-0.5.7 openllm-core-0.5.7\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph langchain langchainhub langchain-core langserve\n",
    "!pip install openllm-client requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92d74045-806d-4c6d-b4bf-fa7fdd4852bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_653065/1534977633.py:53: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama3.3\", temperature=0)\n",
      "LLama3.3 LangGraph Classification: 100%|████████████████████████████████████████████████| 50/50 [02:56<00:00,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Exported predictions to: sdoh_llama3_multiagent_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.llms.ollama import Ollama\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"SDOH_MIMICIII_physio_release.csv\")\n",
    "label_counts = df.drop(columns=[\"provider_type\", \"patient_id\", \"note_id\", \"sentence_index\", \"text\"]).sum()\n",
    "top4_labels = label_counts.sort_values(ascending=False).head(4).index.tolist()\n",
    "df[\"text\"] = df[\"text\"].fillna(\"\")\n",
    "df[top4_labels] = df[top4_labels].fillna(0).astype(int)\n",
    "\n",
    "# Prepare 15% test set\n",
    "_, temp_texts, _, temp_labels = train_test_split(df[\"text\"], df[top4_labels], test_size=0.3, random_state=42)\n",
    "_, test_texts, _, test_labels = train_test_split(temp_texts, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Few-shot examples per agent\n",
    "FEW_SHOT_EXAMPLES = {\n",
    "    \"RELATIONSHIP_married\": [\n",
    "        (\"The patient is married and lives with his wife.\", 1),\n",
    "        (\"He mentioned having no current spouse.\", 0)\n",
    "    ],\n",
    "    \"SUPPORT_plus\": [\n",
    "        (\"She receives strong emotional support from her family.\", 1),\n",
    "        (\"No one is around to support him.\", 0)\n",
    "    ],\n",
    "    \"EMPLOYMENT_employed\": [\n",
    "        (\"He is employed as a construction worker.\", 1),\n",
    "        (\"She is currently unemployed and seeking jobs.\", 0)\n",
    "    ],\n",
    "    \"SUPPORT_minus\": [\n",
    "        (\"Patient reported being socially isolated with no support.\", 1),\n",
    "        (\"She is surrounded by caring friends and family.\", 0)\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Prompt builder\n",
    "def build_prompt(label, sentence):\n",
    "    prompt = (\n",
    "        \"You are a clinical annotation assistant.\\n\"\n",
    "        f\"Determine whether this sentence shows evidence of: {label}\\n\"\n",
    "        \"Reply with 1 if present, 0 if not.\\n\\n\"\n",
    "    )\n",
    "    for example_text, value in FEW_SHOT_EXAMPLES[label]:\n",
    "        prompt += f\"Sentence: {example_text}\\nAnswer: {value}\\n\\n\"\n",
    "    prompt += f\"Sentence: {sentence}\\nAnswer:\"\n",
    "    return prompt\n",
    "\n",
    "# LangGraph agent setup using Ollama llama3.3\n",
    "llm = Ollama(model=\"llama3.3\", temperature=0)\n",
    "\n",
    "def make_agent(label):\n",
    "    def classify(sentence: str):\n",
    "        prompt = build_prompt(label, sentence)\n",
    "        response = llm.invoke(prompt)\n",
    "        return int(response.strip()[0]) if response.strip()[0] in \"01\" else 0\n",
    "    return RunnableLambda(classify)\n",
    "\n",
    "# Create agents\n",
    "agents = {label: make_agent(label) for label in top4_labels}\n",
    "\n",
    "# Classify test data\n",
    "results = []\n",
    "for text in tqdm(test_texts.tolist()[:50], desc=\"LLama3.3 LangGraph Classification\"):\n",
    "    row = {\"text\": text}\n",
    "    for label in top4_labels:\n",
    "        row[f\"{label}_pred\"] = agents[label].invoke(text)\n",
    "    results.append(row)\n",
    "\n",
    "# Final result\n",
    "df_preds = pd.DataFrame(results).reset_index(drop=True)\n",
    "df_preds[[f\"{label}_true\" for label in top4_labels]] = test_labels.reset_index(drop=True)[top4_labels]\n",
    "\n",
    "# Export\n",
    "output_path = \"sdoh_llama3_multiagent_predictions.csv\"\n",
    "df_preds.to_csv(output_path, index=False)\n",
    "print(\"✅ Exported predictions to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f0959f8-4667-4932-ba41-61cd2421c545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Metrics:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "RELATIONSHIP_married       1.00      1.00      1.00         1\n",
      "        SUPPORT_plus       0.00      0.00      0.00         2\n",
      " EMPLOYMENT_employed       0.00      0.00      0.00         0\n",
      "       SUPPORT_minus       0.00      0.00      0.00         0\n",
      "\n",
      "           micro avg       0.12      0.33      0.18         3\n",
      "           macro avg       0.25      0.25      0.25         3\n",
      "        weighted avg       0.33      0.33      0.33         3\n",
      "         samples avg       0.01      0.02      0.01         3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Flatten predictions and true labels\n",
    "y_true = test_labels.reset_index(drop=True)[top4_labels].iloc[:50].values\n",
    "y_pred = df_preds[[f\"{label}_pred\" for label in top4_labels]].values\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true, y_pred, target_names=top4_labels, zero_division=0)\n",
    "print(\"Test Set Metrics:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b909d3-ee93-4a63-85d5-24c6d62c9f96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
